<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Baptiste Pesquet</title>
    <link>https://www.bpesquet.fr/en/</link>
    <description>Recent content on Baptiste Pesquet</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sun, 03 Nov 2019 20:11:05 +0100</lastBuildDate>
    
	<atom:link href="https://www.bpesquet.fr/en/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Python for Data Science</title>
      <link>https://www.bpesquet.fr/en/slides/ai/python-data-science/</link>
      <pubDate>Sat, 28 Sep 2019 21:59:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/python-data-science/</guid>
      <description>Sommaire  Introduction to Data Science Why Python? Python tools for data science  Simplified installation with Anaconda Code and result sharing with Jupyter Notebook Numerical computing with NumPy Data analysis with Pandas Plotting with Matplotlib and Seaborn   Introduction to Data Science What is Data Science?  Main objective: extract insight from data. Expression born in 1997 in the statistician community. &amp;ldquo;A Data Scientist is a statistician that lives in San Francisco&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Machine Learning Fundamentals</title>
      <link>https://www.bpesquet.fr/en/slides/ai/ml-fundamentals/</link>
      <pubDate>Thu, 31 May 2018 09:15:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/ml-fundamentals/</guid>
      <description>Summary  Introduction to Machine Learning Anatomy of a supervised ML system Steps of an ML project  Introduction to Machine Learning A first definition  &amp;ldquo;The field of study that gives computers the ability to learn without being explicitly programmed&amp;rdquo; (Arthur Samuel, 1959).
 Learning machines? Machine Learning is a set of techniques for giving machines the ability to learn from data, in order to:
 Identify or classify elements Detect tendencies Make predictions  As more data is fed into the system, results get better: performance improves with experience.</description>
    </item>
    
    <item>
      <title>ML Algorithms: K-Nearest Neighbors</title>
      <link>https://www.bpesquet.fr/en/slides/ai/k-nearest-neighbors/</link>
      <pubDate>Tue, 24 Sep 2019 09:15:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/k-nearest-neighbors/</guid>
      <description>Summary  K-NN in a nutshell K-NN for classification K-NN for regression  K-NN in a nutshell  Instance-based (no model construction). No training phase, computations happen during predictions. $ \neq $ K-Means algorithm. Very simple yet often efficient. Can be used for classification or regression.  K-NN for classification A new point is assigned to the class which has the most representatives within the k nearest neighbors of the point.</description>
    </item>
    
    <item>
      <title>ML Algorithms: Linear Regression</title>
      <link>https://www.bpesquet.fr/en/slides/ai/linear-regression/</link>
      <pubDate>Wed, 09 Oct 2019 08:37:33 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/linear-regression/</guid>
      <description>Summary  Introduction Analytical Approach: Normal Equation Iterative Approach: Gradient Descent Polynomial Regression Regularization  Introduction Search for a linear relationship between inputs and the output we try to predict.

Problem formulation  Features $ x_i $: properties of a data sample. Parameters $ \theta_i $: coefficients of the linear model. Hypothesis $ \mathcal{h}_\theta $: model output, function of input.  $x^{(i)} = \left\{ x^{(i)}_0, x^{(i)}_1, \dotsc, x^{(i)}_n \right\} \in \mathbf{R}^{n+1} $, with $ x^{(i)}_0 = 0$</description>
    </item>
    
    <item>
      <title>ML Algorithms: Logistic Regression</title>
      <link>https://www.bpesquet.fr/en/slides/ai/logistic-regression/</link>
      <pubDate>Sun, 13 Oct 2019 17:27:01 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/logistic-regression/</guid>
      <description>Summary  Logistic Regression In A Nutshell Binary Classification Multiclass Classification  Logistic Regression in a nutshell  Supervised learning algorithm. Used for classification problems. Linear model + function to transform its output into probabilities. Probabilities are thresholded to predict classes.  Binary classification Uses the logistic (sigmoid) function
The logistic function Output in $[0,1]$

Loss function Binary Crossentropy: $$\mathcal{L}(\theta) = -\frac{1}{m}\sum_{i=1}^m \left[y^{(i)} \log(y&#39;^{(i)}) + (1-y^{(i)}) \log(1-y&#39;^{(i)})\right]$$
(Always convex)</description>
    </item>
    
    <item>
      <title>ML Algorithms: Neural Networks</title>
      <link>https://www.bpesquet.fr/en/slides/ai/neural-networks/</link>
      <pubDate>Thu, 31 May 2018 09:45:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/neural-networks/</guid>
      <description>Summary  Introducing Neural Networks Neural Network Tuning  Introducing Neural Networks The origins  1943 : first mathematical model of a biological neuron (McCulloch &amp;amp; Pitts) 1949 : Hebb&amp;rsquo;s rule 1958 : The perceptron (F. Rosenblatt) 1969 : Limits of perceptrons (M. Minsky)  A biological inspiration McCulloch &amp;amp; Pitts&amp;rsquo; formal neuron Hebb&amp;rsquo;s rule Attempt to explain synaptic plasticity, the adaptation of brain neurons during the learning process.</description>
    </item>
    
    <item>
      <title>ML Algorithms: Ensemble Methods</title>
      <link>https://www.bpesquet.fr/en/slides/ai/ensemble-methods/</link>
      <pubDate>Mon, 21 Oct 2019 08:56:51 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/ensemble-methods/</guid>
      <description>Summary  Decision Trees Ensemble Learning Random Forests Boosting Algorithms  Decision Trees Decision Trees in a nutshell  Supervised method, used for classification or regression. Build a tree-like structure based on a series of questions on the data.  
Example: Iris dataset Tree nodes  Leaf or non-leaf. Gini: measure of the node impurity. Samples: number of samples the node applies to. Value: number of samples of each class the node applies to.</description>
    </item>
    
    <item>
      <title>ML Tools: Keras</title>
      <link>https://www.bpesquet.fr/en/slides/ai/keras/</link>
      <pubDate>Mon, 14 Oct 2019 09:16:40 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/keras/</guid>
      <description>Introducing Keras Python library for creating neural networks created by Fran√ßois Chollet.

High-level, user-friendly API above a ML/DL backend library.
Keras Vs tf.keras  Originally, Keras was multi-backend: TensorFlow 1.x, Theano, CNTK&amp;hellip; Since TF 2.0, tf.keras is the official high-level API of TensorFlow. The 2.3.0 release (Sept. 2019) will be the last major release of multi-backend Keras. TF users should switch to tf.keras.  TF 2.0 + Keras Overview</description>
    </item>
    
    <item>
      <title>ML Tools: PyTorch</title>
      <link>https://www.bpesquet.fr/en/slides/ai/pytorch/</link>
      <pubDate>Sun, 03 Nov 2019 20:11:05 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/pytorch/</guid>
      <description>Summary  PyTorch Essentials Automatic Differentiation In PyTorch Training Models With PyTorch  PyTorch Essentials PyTorch in a nutshell  ML/DL library supported by Facebook. Based on previous work, notably Torch and Chainer. v1.0 in December 2018. Quickly became very popular among DL researchers.  
PyTorch tensors  NumPy-like API for manipulating tensors. Tensors can be located on GPU for faster computations.
import torch a = torch.tensor([5.5, 3]) b = torch.</description>
    </item>
    
    <item>
      <title>Machine Learning Katas</title>
      <link>https://www.bpesquet.fr/en/publication/machine-learning-katas/</link>
      <pubDate>Fri, 22 Mar 2019 11:02:15 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/publication/machine-learning-katas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine Learning Handbook</title>
      <link>https://www.bpesquet.fr/en/publication/machine-learning-handbook/</link>
      <pubDate>Fri, 22 Mar 2019 11:00:45 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/publication/machine-learning-handbook/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Work With Me</title>
      <link>https://www.bpesquet.fr/en/page/work-with-me/</link>
      <pubDate>Thu, 04 Oct 2018 19:02:15 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/page/work-with-me/</guid>
      <description>Real-world projects are great opportunities to apply one&amp;rsquo;s skills and learn something valuable along the way. For this reason, I like to collaborate with external partners whenever possible. These collaborations can take two forms.
Academic partnerships Academic partnerships will involve one or more of my students. They can either be internships (from one to six months) or group projects (from a few weeks to a whole year!). In these partnerships, I usually play the role of a supervisor.</description>
    </item>
    
    <item>
      <title>The JavaScript Way</title>
      <link>https://www.bpesquet.fr/en/publication/the-javascript-way/</link>
      <pubDate>Tue, 22 May 2018 23:26:21 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/publication/the-javascript-way/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Artificial Intelligence on Baptiste Pesquet</title>
    <link>https://www.bpesquet.fr/en/slides/ai/</link>
    <description>Recent content in Artificial Intelligence on Baptiste Pesquet</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="https://www.bpesquet.fr/en/slides/ai/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Deconstructing AI</title>
      <link>https://www.bpesquet.fr/en/slides/ai/deconstructing-ai/</link>
      <pubDate>Mon, 09 Dec 2019 10:47:12 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/deconstructing-ai/</guid>
      <description>Summary  What Is AI, Actually? How Do Machines Learn? Should We Be Scared Of AI?  What Is AI, Actually? The original ambition of AI  &amp;ldquo;AI is the science and engineering of making intelligent machines.&amp;rdquo; (John McCarthy)
&amp;ldquo;Every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.&amp;rdquo; (Dartmouth Workshop, 1956)
&amp;ldquo;AI is the science of making machines do things that would require intelligence if done by men.</description>
    </item>
    
    <item>
      <title>Python for Data Science</title>
      <link>https://www.bpesquet.fr/en/slides/ai/python-data-science/</link>
      <pubDate>Sat, 28 Sep 2019 21:59:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/python-data-science/</guid>
      <description>Sommaire  Introduction to Data Science Why Python? Python tools for data science  Simplified installation with Anaconda Code and result sharing with Jupyter Notebook Numerical computing with NumPy Data analysis with Pandas Plotting with Matplotlib and Seaborn   Introduction to Data Science What is Data Science?  Main objective: extract insight from data. Expression born in 1997 in the statistician community. &amp;ldquo;A Data Scientist is a statistician that lives in San Francisco&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Machine Learning Fundamentals</title>
      <link>https://www.bpesquet.fr/en/slides/ai/ml-fundamentals/</link>
      <pubDate>Thu, 31 May 2018 09:15:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/ml-fundamentals/</guid>
      <description>Summary  Introduction to Machine Learning Anatomy of a supervised ML system Steps of an ML project  Introduction to Machine Learning A first definition  &amp;ldquo;The field of study that gives computers the ability to learn without being explicitly programmed&amp;rdquo; (Arthur Samuel, 1959).
 Learning machines? Machine Learning is a set of techniques for giving machines the ability to learn from data, in order to:
 Identify or classify elements Detect tendencies Make predictions  As more data is fed into the system, results get better: performance improves with experience.</description>
    </item>
    
    <item>
      <title>K-Nearest Neighbors</title>
      <link>https://www.bpesquet.fr/en/slides/ai/k-nearest-neighbors/</link>
      <pubDate>Tue, 24 Sep 2019 09:15:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/k-nearest-neighbors/</guid>
      <description>Summary  K-NN in a nutshell K-NN for classification K-NN for regression  K-NN in a nutshell  Instance-based (no model construction). No training phase, computations happen during predictions. $ \neq $ K-Means algorithm. Very simple yet often efficient. Can be used for classification or regression.  K-NN for classification A new point is assigned to the class which has the most representatives within the k nearest neighbors of the point.</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://www.bpesquet.fr/en/slides/ai/linear-regression/</link>
      <pubDate>Wed, 09 Oct 2019 08:37:33 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/linear-regression/</guid>
      <description>Summary  Introduction Analytical Approach: Normal Equation Iterative Approach: Gradient Descent Polynomial Regression Regularization  Introduction Search for a linear relationship between inputs and the output we try to predict.

Problem formulation  Features $ x_i $: properties of a data sample. Parameters $ \theta_i $: coefficients of the linear model. Hypothesis $ \mathcal{h}_\theta $: model output, function of input.  $x^{(i)} = \left\{ x^{(i)}_0, x^{(i)}_1, \dotsc, x^{(i)}_n \right\} \in \mathbf{R}^{n+1} $, with $ x^{(i)}_0 = 0$</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://www.bpesquet.fr/en/slides/ai/logistic-regression/</link>
      <pubDate>Sun, 13 Oct 2019 17:27:01 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/logistic-regression/</guid>
      <description>Summary  Logistic Regression In A Nutshell Binary Classification Multiclass Classification  Logistic Regression in a nutshell  Supervised learning algorithm. Used for classification problems. Linear model + function to transform its output into probabilities. Probabilities are thresholded to predict classes.  Binary classification Uses the logistic (sigmoid) function
The logistic function Output in $[0,1]$

Loss function Binary Crossentropy: $$\mathcal{L}(\theta) = -\frac{1}{m}\sum_{i=1}^m \left[y^{(i)} \log(y&#39;^{(i)}) + (1-y^{(i)}) \log(1-y&#39;^{(i)})\right]$$
(Always convex)</description>
    </item>
    
    <item>
      <title>Neural Networks</title>
      <link>https://www.bpesquet.fr/en/slides/ai/neural-networks/</link>
      <pubDate>Thu, 31 May 2018 09:45:13 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/neural-networks/</guid>
      <description>Summary  Introducing Neural Networks Neural Network Tuning  Introducing Neural Networks The origins  1943 : first mathematical model of a biological neuron (McCulloch &amp;amp; Pitts) 1949 : Hebb&amp;rsquo;s rule 1958 : The perceptron (F. Rosenblatt) 1969 : Limits of perceptrons (M. Minsky)  A biological inspiration McCulloch &amp;amp; Pitts&amp;rsquo; formal neuron Hebb&amp;rsquo;s rule Attempt to explain synaptic plasticity, the adaptation of brain neurons during the learning process.</description>
    </item>
    
    <item>
      <title>Ensemble Methods</title>
      <link>https://www.bpesquet.fr/en/slides/ai/ensemble-methods/</link>
      <pubDate>Mon, 21 Oct 2019 08:56:51 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/ensemble-methods/</guid>
      <description>Summary  Decision Trees Ensemble Learning Random Forests Boosting Algorithms  Decision Trees Decision Trees in a nutshell  Supervised method, used for classification or regression. Build a tree-like structure based on a series of questions on the data.  
Example: Iris dataset Tree nodes  Leaf or non-leaf. Gini: measure of the node impurity. Samples: number of samples the node applies to. Value: number of samples of each class the node applies to.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Networks</title>
      <link>https://www.bpesquet.fr/en/slides/ai/convolutional-neural-networks/</link>
      <pubDate>Thu, 17 Jan 2019 00:02:17 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/convolutional-neural-networks/</guid>
      <description>Summary  CNN Architecture CNN History  CNN Architecture Justification The visual world has the following properties:
 Translation invariance. Spatial hierarchy: complex and abstract concepts are composed from simple elements.  Classical models are not designed to detect local patterns in images.
General Design 
The convolution operation Apply a filter or kernel to data. Result is called a feature map.

Convolution parameters  Filter dimensions: 2D for images.</description>
    </item>
    
    <item>
      <title>Generative Deep Learning</title>
      <link>https://www.bpesquet.fr/en/slides/ai/generative-deep-learning/</link>
      <pubDate>Mon, 11 Nov 2019 22:13:47 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/generative-deep-learning/</guid>
      <description>Summary  Neural Style Transfer Generative Adversarial Networks (GAN)  Neural Style Transfer Neural Style Transfer in a nutshell  Reproduce an image with a new artistic style provided by another image. Blend a content image and a style reference image in a stylized output image. First described in A Neural Algorithm of Artistic Style by Gatys et al (2015). Many refinements and variations since.  Example (Prisma app)</description>
    </item>
    
    <item>
      <title>Keras</title>
      <link>https://www.bpesquet.fr/en/slides/ai/keras/</link>
      <pubDate>Mon, 14 Oct 2019 09:16:40 +0200</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/keras/</guid>
      <description>Summary  Introduction to Keras Dense Neural Networks Neural Network Tuning Convolutional Neural Networks  Introduction to Keras Keras in a nutshell Python library for creating neural networks created by Fran√ßois Chollet.

High-level, user-friendly API above a ML/DL backend library.
Keras Vs tf.keras  Originally, Keras was multi-backend: TensorFlow 1.x, Theano, CNTK&amp;hellip; Since TF 2.0, tf.keras is the official high-level API of TensorFlow. The 2.3.0 release (Sept. 2019) will be the last major release of multi-backend Keras.</description>
    </item>
    
    <item>
      <title>PyTorch</title>
      <link>https://www.bpesquet.fr/en/slides/ai/pytorch/</link>
      <pubDate>Sun, 03 Nov 2019 20:11:05 +0100</pubDate>
      
      <guid>https://www.bpesquet.fr/en/slides/ai/pytorch/</guid>
      <description>Summary  Introduction To PyTorch Automatic Differentiation Dense Neural Networks Convolutional Neural Networks  Introduction To PyTorch PyTorch in a nutshell  ML/DL platform supported by Facebook. Core components:  A tensor manipulation library similar to NumPy. An autodiff engine for computing gradients. A neural network API.  Based on previous work, notably Torch and Chainer. Initial release in Oct. 2016, v1.0 in Dec. 2018. Quickly became popular among DL researchers.</description>
    </item>
    
  </channel>
</rss>